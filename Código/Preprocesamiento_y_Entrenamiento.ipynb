{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,  OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos los datos\n",
    "Data = pd.read_csv(\"../Datos/data_adults.csv\")\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Vista rápida de los datos\n",
    "print(Data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas irrelevantes\n",
    "Data_cop = Data.drop(\"fnlwgt\", axis=1)\n",
    "Data_cop = Data_cop.drop(\"education-num\", axis=1)\n",
    "X = Data_cop.drop(\"income\", axis=1)\n",
    "y = Data_cop['income'].isin(['>50K.','>50K'])\n",
    "# Definimos las variables categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Creamos pipelines de preprocesamiento\n",
    "\n",
    "# Pipeline RL, Naive Bayes y Gradient Boosting\n",
    "numerical_transformer_1 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_1 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pipeline SVM\n",
    "numerical_transformer_2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('svd', TruncatedSVD(n_components=50, random_state=25))\n",
    "])\n",
    "# Usamos ColumnTransformer para combinar ambas transformaciones\n",
    "preprocessor_1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_1, numerical_features),\n",
    "        ('cat', categorical_transformer_1, categorical_features)\n",
    "    ])\n",
    "\n",
    "# \n",
    "preprocessor_2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_2, numerical_features),\n",
    "        ('cat', categorical_transformer_2, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el pipeline completo\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1)])\n",
    "model_pipeline_svm = Pipeline(steps=[('preprocessor', preprocessor_2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.93      0.90      7414\n",
      "        True       0.74      0.58      0.65      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n",
      "Mejores parámetros encontrados: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lr_pipeline_op.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_1),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Definimos la búsqueda de hiperparámetros\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],\n",
    "    'classifier__penalty': ['l2', 'none'],\n",
    "    'classifier__solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "# Instanciamos la búsqueda del mejor modelo\n",
    "lr_busqueda = GridSearchCV(estimator=lr_pipeline,\n",
    "                            param_grid=param_grid_lr,\n",
    "                            cv=3,\n",
    "                            verbose=4,\n",
    "                            scoring='f1',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# Entrenamos el pipeline con búsqueda de hiperparámetros en los datos de entrenamiento\n",
    "lr_busqueda.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred = lr_busqueda.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(lr_busqueda.best_estimator_, 'lr_pipeline.joblib')\n",
    "\n",
    "# Accedemos a los mejores parámetros\n",
    "mejores_parametros = lr_busqueda.best_params_\n",
    "print(\"Mejores parámetros encontrados:\", mejores_parametros)\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(lr_pipeline, 'lr_pipeline_op.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo normal / Sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.93      0.90      7414\n",
      "        True       0.74      0.58      0.65      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lr_pipeline.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1),\n",
    "                                 ('classifier', LogisticRegression(random_state=42))])\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(lr_pipeline, 'lr_pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo normal/sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.94      0.90      7414\n",
      "        True       0.75      0.55      0.64      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_pipeline.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importamos warnings para evitar los mensajes de advertencia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "svm_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1),\n",
    "                                 ('classifier', SVC(kernel = \"linear\", C= 1.0, random_state=42))])\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(svm_pipeline, 'svm_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.94      0.90      7414\n",
      "        True       0.75      0.55      0.64      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_pipeline_op.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importamos warnings para evitar los mensajes de advertencia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "svm_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1),\n",
    "                                 ('classifier', SVC(kernel = \"linear\", C= 1.0, random_state=42))])\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "svm_busqueda = GridSearchCV(estimator=svm_pipeline,\n",
    "                             param_grid=param_grid_svm,\n",
    "                             cv=3,\n",
    "                             verbose=4,\n",
    "                             scoring='f1',\n",
    "                             n_jobs=-1)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(svm_pipeline, 'svm_pipeline_op.joblib')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.82      0.86      7414\n",
      "        True       0.56      0.74      0.64      2355\n",
      "\n",
      "    accuracy                           0.80      9769\n",
      "   macro avg       0.73      0.78      0.75      9769\n",
      "weighted avg       0.82      0.80      0.81      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gnb_pipeline.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "gnb_pipeline = Pipeline(steps=[('preprocessor', preprocessor_2),\n",
    "                                 ('classifier', GaussianNB())])\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "gnb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = gnb_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(gnb_pipeline, 'gnb_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con optimización de hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.96      0.91      7414\n",
      "        True       0.80      0.57      0.67      2355\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.84      0.76      0.79      9769\n",
      "weighted avg       0.86      0.86      0.85      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gradboost_pipeline_op.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "gradboost_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1),\n",
    "                                 ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))])\n",
    "\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "gradboost_pipeline.fit(X_train, y_train)\n",
    "\n",
    "param_grid_gb = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "gradboostb_busqueda = GridSearchCV(estimator=gradboost_pipeline,\n",
    "                            param_grid=param_grid_gb,\n",
    "                            cv=3,\n",
    "                            verbose=4,\n",
    "                            scoring='f1',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = gradboost_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(gradboost_pipeline, 'gradboost_pipeline_op.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo normal/sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.96      0.91      7414\n",
      "        True       0.80      0.57      0.67      2355\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.84      0.76      0.79      9769\n",
      "weighted avg       0.86      0.86      0.85      9769\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gradboost_pipeline.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Creamos un nuevo pipeline que incluye el preprocesamiento y el modelo\n",
    "gradboost_pipeline = Pipeline(steps=[('preprocessor', preprocessor_1),\n",
    "                                 ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Entrenamos el pipeline completo en los datos de entrenamiento\n",
    "gradboost_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = gradboost_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardamos el pipeline completo (preprocesamiento + modelo entrenado)\n",
    "dump(gradboost_pipeline, 'gradboost_pipeline.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarea1-K0N5MVTn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
